# 0x11. Attention

- 0. RNN Encoder

- 1. Self Attention

- 2. RNN Decoder

- 3. Positional Encoding

- 4. Scaled Dot Product Attention

- 5. Multi Head Attention

- 6. Transformer Encoder Block

- 7. Transformer Decoder Block

- 8. Transformer Encoder

- 9. Transformer Decoder

- 10. Transformer Network
